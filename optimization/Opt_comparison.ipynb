{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting initial variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from constants import DURATION_BX, VDRIFT\n",
    "from mappings import Mapping\n",
    "from timeit import timeit\n",
    "import tracemalloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FNAME = \"../config/RUN000054.yml\"\n",
    "DATA_FNAME = \"../data/RUN000054_data100.txt\"\n",
    "\n",
    "with open(CONFIG_FNAME, \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "dtype_dict = { 'HEAD':np.uint8, 'FPGA':np.uint8, 'TDC_CHANNEL':np.uint8, 'ORBIT_CNT':np.uint64, 'BX_COUNTER':np.uint16, 'TDC_MEAS':np.uint8 }\n",
    "stream_df = pd.read_csv(DATA_FNAME, dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mappings.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import XCELL, X_POS_SHIFT, Z_POS_SHIFT\n",
    "\n",
    "class Mapping_o(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def sl_map(self, df):\n",
    "        \"\"\"\n",
    "        Add columns with SL, LAYER, WIRE_NUM, WIRE_POS\n",
    "        for local coordinates\n",
    "        Args:\n",
    "            - df  : Pandas dataframe of hits\n",
    "            - cfg : configuration dict for this run\n",
    "        \"\"\"\n",
    "        #print(\"local mapping...\")\n",
    "        # assing SL to each hit\n",
    "        # sl_cfg is similar to {\"fpga\": 0, \"ch_start\": 0, \"ch_end\": 63}\n",
    "        for sl, sl_cfg in self.cfg[\"sl_mapping\"].items():\n",
    "            sl_mask = (\n",
    "                (df[\"FPGA\"] == sl_cfg[\"fpga\"])\n",
    "                & (df[\"TDC_CHANNEL\"] >= sl_cfg[\"ch_start\"])\n",
    "                & (df[\"TDC_CHANNEL\"] <= sl_cfg[\"ch_end\"])\n",
    "            )\n",
    "            df.loc[sl_mask, \"SL\"] = sl\n",
    "        \n",
    "        # create the layer column (layer 4 is the top one)\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 0), \"LAYER\"] = 4\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 2), \"LAYER\"] = 3\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 1), \"LAYER\"] = 2\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 3), \"LAYER\"] = 1\n",
    "\n",
    "        df = df.astype({\"SL\": \"uint8\", \"LAYER\": \"uint8\"})\n",
    "        # set the wire num inside the layer: ranging from 1 to 16 (left to right)\n",
    "        # tdc_channel is normalized from 0->63 for each sl\n",
    "        # assign the wire position\n",
    "        for layer in [1, 2, 3, 4]:\n",
    "            # local wire x position\n",
    "            df.loc[df[\"LAYER\"] == layer, \"WIRE_X_LOC\"] = (\n",
    "                df[\"TDC_CHANNEL\"] % 64 // 4\n",
    "            ) * XCELL + X_POS_SHIFT[layer]\n",
    "\n",
    "            # local wire z position\n",
    "            df.loc[df[\"LAYER\"] == layer, \"WIRE_Z_LOC\"] = Z_POS_SHIFT[layer]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def global_map(self, df):\n",
    "        \"\"\"\n",
    "        Create global coordinates based on the SL geometry\n",
    "        adopted in the selected run\n",
    "        Args:\n",
    "            - df  : Pandas dataframe of hits\n",
    "            - cfg : configuration dict for this run\n",
    "        \"\"\"\n",
    "        # build the map for each sl\n",
    "        df = self.sl_map(df)\n",
    "        #print(\"global mapping...\")\n",
    "        # place wire in the space\n",
    "        for sl, sl_shift in self.cfg[\"sl_shift\"].items():\n",
    "            # shift z\n",
    "            df.loc[df[\"SL\"] == sl, \"WIRE_Z_GLOB\"] = df[\"WIRE_Z_LOC\"] + sl_shift[\"z\"]\n",
    "\n",
    "            # shift x\n",
    "            df.loc[df[\"SL\"] == sl, \"WIRE_X_GLOB\"] = df[\"WIRE_X_LOC\"] + sl_shift[\"x\"]\n",
    "\n",
    "            # shift y -> not implemented\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "def prepare_for_mapping(stream_df):\n",
    "    #drop NaN\n",
    "    stream_df = stream_df.dropna()\n",
    "\n",
    "    # create a dataframe with only valid hits ->\n",
    "    # trigger words and scintillator hits are removed\n",
    "    hits_df = stream_df[\n",
    "        (stream_df.HEAD == cfg[\"headers\"][\"valid_hit\"]) &\n",
    "        (stream_df.TDC_CHANNEL <= 127)\n",
    "        ]\n",
    "     \n",
    "    # select all orbits with a trigger signal from\n",
    "    # the scintillators coincidence\n",
    "    trigger_df = stream_df[\n",
    "        (stream_df[\"HEAD\"] == cfg[\"scintillator\"][\"head\"]) & \n",
    "        (stream_df[\"FPGA\"] == cfg[\"scintillator\"][\"fpga\"]) & \n",
    "        (stream_df[\"TDC_CHANNEL\"] == cfg[\"scintillator\"][\"tdc_ch\"])\n",
    "    ]\n",
    "\n",
    "    del stream_df\n",
    "\n",
    "    # create a T0 column (in ns)\n",
    "    trigger_df[\"T0_NS\"] = (trigger_df[\"BX_COUNTER\"] + trigger_df[\"TDC_MEAS\"] / 30) * DURATION_BX\n",
    "\n",
    "    # select only hits in the same orbit of a scint trigger signal\n",
    "    hits_df_ = pd.merge(\n",
    "        hits_df, trigger_df[[\"ORBIT_CNT\",\"T0_NS\"]],\n",
    "        left_on=\"ORBIT_CNT\", right_on=\"ORBIT_CNT\",\n",
    "        suffixes=(None, None)\n",
    "    )\n",
    "\n",
    "    del trigger_df\n",
    "    del hits_df\n",
    "    return hits_df_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import XCELL, X_POS_SHIFT, Z_POS_SHIFT\n",
    "\n",
    "class Mapping_no(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def sl_map(self, df):\n",
    "        \"\"\"\n",
    "        Add columns with SL, LAYER, WIRE_NUM, WIRE_POS\n",
    "        for local coordinates\n",
    "        Args:\n",
    "            - df  : Pandas dataframe of hits\n",
    "            - cfg : configuration dict for this run\n",
    "        \"\"\"\n",
    "\n",
    "        # assing SL to each hit\n",
    "        # sl_cfg is similar to {\"fpga\": 0, \"ch_start\": 0, \"ch_end\": 63}\n",
    "        for sl, sl_cfg in self.cfg[\"sl_mapping\"].items():\n",
    "            sl_mask = (\n",
    "                (df[\"FPGA\"] == sl_cfg[\"fpga\"])\n",
    "                & (df[\"TDC_CHANNEL\"] >= sl_cfg[\"ch_start\"])\n",
    "                & (df[\"TDC_CHANNEL\"] <= sl_cfg[\"ch_end\"])\n",
    "            )\n",
    "            df.loc[sl_mask, \"SL\"] = sl\n",
    "\n",
    "        # create the layer column (layer 4 is the top one)\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 0), \"LAYER\"] = 4\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 2), \"LAYER\"] = 3\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 1), \"LAYER\"] = 2\n",
    "        df.loc[(df[\"TDC_CHANNEL\"] % 4 == 3), \"LAYER\"] = 1\n",
    "\n",
    "        # set the wire num inside the layer: ranging from 1 to 16 (left to right)\n",
    "        # in tdc_channel_norm the channel is normalized from 0->63 for each sl\n",
    "        df[\"TDC_CHANNEL_NORM\"] = df[\"TDC_CHANNEL\"] % 64  # .astype(np.uint8)\n",
    "        df[\"WIRE_NUM\"] = df[\"TDC_CHANNEL_NORM\"] // 4 + 1  # .astype(np.uint8)\n",
    "\n",
    "        # assign the wire position\n",
    "        for layer in [1, 2, 3, 4]:\n",
    "            # local wire x position\n",
    "            df.loc[df[\"LAYER\"] == layer, \"WIRE_X_LOC\"] = (\n",
    "                df[\"WIRE_NUM\"] - 1\n",
    "            ) * XCELL + X_POS_SHIFT[layer]\n",
    "\n",
    "            # local wire z position\n",
    "            df.loc[df[\"LAYER\"] == layer, \"WIRE_Z_LOC\"] = Z_POS_SHIFT[layer]\n",
    "\n",
    "        df = df.astype({\"SL\": \"int8\", \"LAYER\": \"int8\"})\n",
    "        return df\n",
    "\n",
    "    def global_map(self, df):\n",
    "        \"\"\"\n",
    "        Create global coordinates based on the SL geometry\n",
    "        adopted in the selected run\n",
    "        Args:\n",
    "            - df  : Pandas dataframe of hits\n",
    "            - cfg : configuration dict for this run\n",
    "        \"\"\"\n",
    "        # build the map for each sl\n",
    "        df = self.sl_map(df)\n",
    "\n",
    "        # place wire in the space\n",
    "        for sl, sl_shift in self.cfg[\"sl_shift\"].items():\n",
    "            # shift z\n",
    "            df.loc[df[\"SL\"] == sl, \"WIRE_Z_GLOB\"] = df[\"WIRE_Z_LOC\"] + sl_shift[\"z\"]\n",
    "\n",
    "            # shift x\n",
    "            df.loc[df[\"SL\"] == sl, \"WIRE_X_GLOB\"] = df[\"WIRE_X_LOC\"] + sl_shift[\"x\"]\n",
    "\n",
    "            # shift y -> not implemented\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not optimized:\n",
      "Time 0.07586992280121194 s, Memory 12.858104 MB\n",
      "Optimized:\n",
      "Time 0.13954538560064975 s, Memory 8.709441 MB\n"
     ]
    }
   ],
   "source": [
    "n_iter    = 5\n",
    "mapper_o  = Mapping_o(cfg)\n",
    "mapper_no = Mapping_no(cfg)\n",
    "map_df_o  = prepare_for_mapping(stream_df)\n",
    "map_df_no = prepare_for_mapping(stream_df)\n",
    "\n",
    "tracemalloc.start()\n",
    "t_o        = timeit('mapper_o.global_map(map_df_o)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_o  = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.reset_peak()\n",
    "\n",
    "t_no       = timeit('mapper_no.global_map(map_df_no)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_no = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"Not optimized:\\nTime {0} s, Memory {1} MB\\nOptimized:\\nTime {2} s, Memory {3} MB\".format(t_no, peak_no/10**6, t_o, peak_o/10**6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EventsFactory.py\n",
    "### Reading df from file comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not optimized:\n",
      "Time 1.3509621144010453 s, Memory 326.82871 MB\n",
      "Optimized:\n",
      "Time 1.3727195213999948 s, Memory 122.58949 MB\n"
     ]
    }
   ],
   "source": [
    "dtype_dict = { 'HEAD':np.uint8, 'FPGA':np.uint8, 'TDC_CHANNEL':np.uint8, 'ORBIT_CNT':np.uint64, 'BX_COUNTER':np.uint16, 'TDC_MEAS':np.uint8 }\n",
    "n_iter     = 5\n",
    "\n",
    "tracemalloc.start()\n",
    "tr_o        = timeit('pd.read_csv(DATA_FNAME, dtype=dtype_dict)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_o  = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.reset_peak()\n",
    "\n",
    "tr_no       = timeit('pd.read_csv(DATA_FNAME)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_no = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"Not optimized:\\nTime {0} s, Memory {1} MB\\nOptimized:\\nTime {2} s, Memory {3} MB\".format(tr_no, peak_no/10**6, tr_o, peak_o/10**6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GetEvents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import DURATION_BX, VDRIFT\n",
    "\n",
    "\n",
    "def map_hit_position(hits_df_, local=False):\n",
    "    \"\"\"\n",
    "    Compute the position of the hit.\n",
    "    If local=True the positions left/right will \n",
    "    be computed in the local frame of reference\n",
    "    (e.g. X_LEFT_LOC). Else, the positions will be\n",
    "    computed in the global frame of reference\n",
    "    \"\"\"\n",
    "\n",
    "    hits_df_[\"HIT_DRIFT_TIME\"] = (hits_df_[\"BX_COUNTER\"]+hits_df_[\"TDC_MEAS\"]/30)*DURATION_BX-hits_df_[\"T0_NS\"]\n",
    "\n",
    "    ref = \"LOC\" if local else \"GLOB\"\n",
    "    hits_df_[f\"X_LEFT_{ref}\"] = hits_df_[f\"WIRE_X_{ref}\"] - hits_df_[\"HIT_DRIFT_TIME\"]*VDRIFT\n",
    "    hits_df_[f\"X_RIGHT_{ref}\"] = hits_df_[f\"WIRE_X_{ref}\"] + hits_df_[\"HIT_DRIFT_TIME\"]*VDRIFT\n",
    "\n",
    "    return hits_df_\n",
    "\n",
    "\n",
    "def computeEvents_o(hits_df_):\n",
    "    events = [group for _, group in hits_df_.groupby(\"ORBIT_CNT\") if len(group) <= 32]\n",
    "    return events\n",
    "\n",
    "\n",
    "def getEvents_o(df_fname, cfg, runTimeShift):\n",
    "    \n",
    "    #reading df from file\n",
    "    dtype_dict = { 'HEAD':np.uint8, 'FPGA':np.uint8, 'TDC_CHANNEL':np.uint8, 'ORBIT_CNT':np.uint64, 'BX_COUNTER':np.uint16, 'TDC_MEAS':np.uint8 }\n",
    "    #print(\"Reading dataset from file...\")\n",
    "    stream_df = pd.read_csv(df_fname, dtype=dtype_dict)\n",
    "    #drop NaN\n",
    "    stream_df.dropna(inplace=True)\n",
    "\n",
    "    # create a dataframe with only valid hits ->\n",
    "    # trigger words and scintillator hits are removed\n",
    "    hits_df = stream_df[\n",
    "        (stream_df.HEAD == cfg[\"headers\"][\"valid_hit\"]) &\n",
    "        (stream_df.TDC_CHANNEL <= 127)\n",
    "        ]\n",
    "     \n",
    "    # select all orbits with a trigger signal from\n",
    "    # the scintillators coincidence\n",
    "    trigger_df = stream_df[\n",
    "        (stream_df[\"HEAD\"] == cfg[\"scintillator\"][\"head\"]) & \n",
    "        (stream_df[\"FPGA\"] == cfg[\"scintillator\"][\"fpga\"]) & \n",
    "        (stream_df[\"TDC_CHANNEL\"] == cfg[\"scintillator\"][\"tdc_ch\"])\n",
    "    ]\n",
    "\n",
    "    del stream_df\n",
    "\n",
    "    # create a T0 column (in ns)\n",
    "    trigger_df[\"T0_NS\"] = (trigger_df[\"BX_COUNTER\"] + trigger_df[\"TDC_MEAS\"] / 30) * DURATION_BX\n",
    "\n",
    "    # select only hits in the same orbit of a scint trigger signal\n",
    "    hits_df_ = pd.merge(\n",
    "        hits_df, trigger_df[[\"ORBIT_CNT\",\"T0_NS\"]],\n",
    "        left_on=\"ORBIT_CNT\", right_on=\"ORBIT_CNT\",\n",
    "        suffixes=(None, None)\n",
    "    )\n",
    "\n",
    "    del trigger_df\n",
    "    del hits_df\n",
    "    # print the number of valid hits found in data\n",
    "    print(f\"Valid hits: {hits_df_.shape[0]}\")\n",
    "\n",
    "    # create mapping with the loaded configurations\n",
    "    mapper = Mapping_o(cfg)\n",
    "    # map hits\n",
    "    hits_df_ = mapper.global_map(hits_df_)\n",
    "\n",
    "    # TIME SHIFTING\n",
    "    # apply scintillator calibration -> they shoul be computed\n",
    "    # for each run! For this example run, values are provided in\n",
    "    # the configurations file.\n",
    "\n",
    "    for sl, offset_sl in cfg[\"time_offset_sl\"].items():\n",
    "        # correction is in the form:\n",
    "        # coarse offset valid for all SL + fine tuning \n",
    "        hits_df_.loc[\n",
    "            hits_df_[\"SL\"] == sl, \"T0_NS\"\n",
    "        ] -= cfg[\"time_offset_scint\"] -runTimeShift + offset_sl # 6 for 123, 8 for 0\n",
    "\n",
    "    # having the time allows us to compute hit position \n",
    "    # with left / right ambiguity\n",
    "\n",
    "    hits_df_ = map_hit_position(hits_df_, local=False)\n",
    "\n",
    "    return computeEvents_o(hits_df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Not Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeEvents_no(hits_df_):\n",
    "    events = []\n",
    "    for x in pd.unique(hits_df_.ORBIT_CNT):\n",
    "        events.append(hits_df_[hits_df_[\"ORBIT_CNT\"] == x])\n",
    "        events[-1] = events[-1].reset_index(drop=True)\n",
    "    return events\n",
    "\n",
    "\n",
    "def getEvents_no(stream_df, cfg, runTimeShift):\n",
    "    \n",
    "    # create a dataframe with only valid hits ->\n",
    "    # trigger words and scintillator hits are removed\n",
    "    hits_df = stream_df[\n",
    "        (stream_df.HEAD == cfg[\"headers\"][\"valid_hit\"]) &\n",
    "        (stream_df.TDC_CHANNEL <= 127)\n",
    "        ].copy()\n",
    "\n",
    "    # fix TDC_MEAS data type\n",
    "    hits_df = hits_df.dropna()\n",
    "    hits_df = hits_df.astype({\"TDC_MEAS\": \"int32\"})\n",
    "\n",
    "    # create mapping with the loaded configurations\n",
    "    mapper = Mapping_no(cfg)\n",
    "\n",
    "    # map hits\n",
    "    hits_df = mapper.global_map(hits_df)\n",
    "\n",
    "    # select all orbits with a trigger signal from\n",
    "    # the scintillators coincidence\n",
    "    trigger_df = stream_df[\n",
    "        (stream_df[\"HEAD\"] == cfg[\"scintillator\"][\"head\"]) & \n",
    "        (stream_df[\"FPGA\"] == cfg[\"scintillator\"][\"fpga\"]) & \n",
    "        (stream_df[\"TDC_CHANNEL\"] == cfg[\"scintillator\"][\"tdc_ch\"])\n",
    "    ].copy()\n",
    "\n",
    "    # create a T0 column (in ns)\n",
    "    trigger_df[\"T0\"] = (trigger_df[\"BX_COUNTER\"] + trigger_df[\"TDC_MEAS\"] / 30)\n",
    "\n",
    "    # select only hits in the same orbit of a scint trigger signal\n",
    "    hits_df_ = pd.merge(\n",
    "        hits_df, trigger_df[[\"ORBIT_CNT\",\"T0\"]],\n",
    "        left_on=\"ORBIT_CNT\", right_on=\"ORBIT_CNT\",\n",
    "        suffixes=(None, None)\n",
    "    )\n",
    "    # print the number of valid hits found in data\n",
    "    print(f\"Valid hits: {hits_df_.shape[0]}\")\n",
    "\n",
    "    # TIME SHIFTING\n",
    "    # apply scintillator calibration -> they shoul be computed\n",
    "    # for each run! For this example run, values are provided in\n",
    "    # the configurations file.\n",
    "\n",
    "    # create a time column in NS\n",
    "    hits_df_[\"T0_NS\"] = hits_df_[\"T0\"] * DURATION_BX\n",
    "\n",
    "    for sl, offset_sl in cfg[\"time_offset_sl\"].items():\n",
    "        # correction is in the form:\n",
    "        # coarse offset valid for all SL + fine tuning \n",
    "        hits_df_.loc[\n",
    "            hits_df_[\"SL\"] == sl, \"T0_NS\"\n",
    "        ] -= cfg[\"time_offset_scint\"] -runTimeShift + offset_sl # 6 for 123, 8 for 0\n",
    "\n",
    "    # having the time allows us to compute hit position \n",
    "    # with left / right ambiguity\n",
    "\n",
    "    hits_df_ = map_hit_position(hits_df_, local=False)\n",
    "\n",
    "    return computeEvents_no(hits_df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid hits: 54952\n",
      "Valid hits: 54952\n",
      "Not optimized:\n",
      "Time 7.853843677003169 s, Memory 689.836867 MB\n",
      "Optimized:\n",
      "Time 0.7442496255986044 s, Memory 252.461793 MB\n"
     ]
    }
   ],
   "source": [
    "n_iter    = 1\n",
    "stream_df = pd.read_csv(DATA_FNAME, dtype=dtype_dict)\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "t_no       = timeit('getEvents_no(stream_df, cfg, 0)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_no = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.reset_peak()\n",
    "\n",
    "t_o       = timeit('getEvents_o(DATA_FNAME, cfg, 0)', number = n_iter, globals=globals()) / n_iter - tr_o\n",
    "_, peak_o = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"Not optimized:\\nTime {0} s, Memory {1} MB\\nOptimized:\\nTime {2} s, Memory {3} MB\".format(t_no, peak_no/10**6, t_o, peak_o/10**6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reco.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.indexes.numeric import IntegerIndex\n",
    "from scipy import optimize\n",
    "from numpy import sqrt\n",
    "\n",
    "\n",
    "# *****************************************************************************\n",
    "# LINEAR_REG\n",
    "# *****************************************************************************\n",
    "\n",
    "\n",
    "def chisq(X, Y, SY, a, b):\n",
    "    return sum(((y - a - x * b) / sy) ** 2 for x, y, sy in zip(X, Y, SY))\n",
    "\n",
    "\n",
    "def fitfunc(x, a, b):\n",
    "    return a + b * x\n",
    "\n",
    "\n",
    "def linear_reg(X, Y):\n",
    "\n",
    "    sigma_X = [0.4] * len(X)  # 400 um std\n",
    "    mGuess = 100 if ((X[0] - X[1]) == 0) else (Y[0] - Y[1]) / (X[0] - X[1])\n",
    "    qGuess = Y[0] - mGuess * X[0]\n",
    "    p_init = [qGuess, mGuess]  # valori iniziali\n",
    "    p_best, pcov = optimize.curve_fit(fitfunc, Y, X, sigma=sigma_X, p0=p_init)\n",
    "\n",
    "    chi2 = chisq(Y, X, sigma_X, p_best[0], p_best[1])\n",
    "    dof = len(X) - 2  # - 1\n",
    "    chisq_comp = abs(chi2 - dof) / sqrt(2 * dof)\n",
    "\n",
    "    m = p_best[1]\n",
    "    q = p_best[0]\n",
    "    return {\"m\": m, \"q\": q, \"chisq_comp\": chisq_comp}\n",
    "\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def compute_o(df): \n",
    "    \n",
    "    comb = []\n",
    "    if len(df.LAYER.unique()) == 3:\n",
    "        comb.append(df)\n",
    "        tot_Hits = 3\n",
    "    else:\n",
    "        for index in list(combinations(df.index, 4)):\n",
    "            if len(df.loc[index, :].LAYER.unique()) == 4:\n",
    "                comb.append(df.loc[index, :]) \n",
    "        tot_Hits = 4\n",
    "\n",
    "    min_lambda = np.finfo(float).max\n",
    "\n",
    "    for data in comb:\n",
    "        X = np.array(pd.concat([data[\"X_RIGHT_GLOB\"], data[\"X_LEFT_GLOB\"]]))\n",
    "        Y = np.array(pd.concat([data[\"WIRE_Z_GLOB\"], data[\"WIRE_Z_GLOB\"]]))\n",
    "        for indexes_comb in list(combinations(range(len(X)), tot_Hits)):\n",
    "            indexes_comb = list(indexes_comb)\n",
    "            if len(np.unique(Y[indexes_comb])) == tot_Hits:\n",
    "                regr_dict = linear_reg(X[indexes_comb], Y[indexes_comb])\n",
    "                if abs(regr_dict[\"chisq_comp\"]) < min_lambda:\n",
    "                    min_lambda = abs(regr_dict[\"chisq_comp\"])\n",
    "                    xdata = X[indexes_comb]\n",
    "                    res_dict = regr_dict\n",
    "                    best_comb = indexes_comb\n",
    "                    best_data = data\n",
    "\n",
    "    reco_df = pd.concat([best_data, best_data], axis=0, ignore_index=True)\n",
    "    reco_df = reco_df.loc[best_comb, :]\n",
    "    reco_df[\"m\"] = np.full(len(reco_df), res_dict[\"m\"])\n",
    "    reco_df[\"q\"] = np.full(len(reco_df), res_dict[\"q\"])\n",
    "    reco_df[\"X\"] = xdata\n",
    "    if xdata is None: return\n",
    "\n",
    "    return reco_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_no(df):\n",
    "    \n",
    "    comb = []\n",
    "    if len(df.LAYER.unique()) == 3:\n",
    "        comb.append(df)\n",
    "        tot_Hits = 3\n",
    "    else:\n",
    "        for index in list(combinations(df.index, 4)):\n",
    "            tmp_df = df.loc[index, :]\n",
    "            if len(tmp_df.LAYER.unique()) == 4:\n",
    "                comb.append(tmp_df)  # comb[] contains combinations of data\n",
    "        tot_Hits = 4\n",
    "\n",
    "    # saving ORBIT_CNT\n",
    "    orbit = np.array(df[\"ORBIT_CNT\"])[0]\n",
    "\n",
    "    # saving SL\n",
    "    sl = np.array(df[\"SL\"])[0]\n",
    "\n",
    "    flag = True\n",
    "\n",
    "    for data in comb:\n",
    "        X = np.array(pd.concat([data[\"X_RIGHT_GLOB\"], data[\"X_LEFT_GLOB\"]]))\n",
    "        Y = np.array(pd.concat([data[\"WIRE_Z_GLOB\"], data[\"WIRE_Z_GLOB\"]]))\n",
    "        for indexes_comb in list(combinations(range(len(X)), tot_Hits)):\n",
    "            new_X = []\n",
    "            new_Y = []\n",
    "            for i in indexes_comb:\n",
    "                new_X.append(X[i])\n",
    "                new_Y.append(Y[i])\n",
    "\n",
    "            if len(np.unique(new_Y)) == tot_Hits:\n",
    "                regr_tuple = linear_reg(new_X, new_Y)\n",
    "                if flag:\n",
    "                    min_lambda = abs(regr_tuple[\"chisq_comp\"])\n",
    "                    xdata = new_X\n",
    "                    ydata = new_Y\n",
    "                    res_dict = regr_tuple\n",
    "                    flag = False\n",
    "                    best_comb = indexes_comb\n",
    "                    best_data = data\n",
    "                elif abs(regr_tuple[\"chisq_comp\"]) < min_lambda:\n",
    "                    best_comb = indexes_comb\n",
    "                    min_lambda = abs(regr_tuple[\"chisq_comp\"])\n",
    "                    xdata = new_X\n",
    "                    ydata = new_Y\n",
    "                    res_dict = regr_tuple\n",
    "                    best_data = data\n",
    "\n",
    "    big_df = pd.concat([best_data, best_data], axis=0, ignore_index=True)\n",
    "    reco_df = big_df.loc[best_comb, :]\n",
    "    reco_df[\"m\"] = np.full(len(reco_df), res_dict[\"m\"])\n",
    "    reco_df[\"q\"] = np.full(len(reco_df), res_dict[\"q\"])\n",
    "    reco_df[\"X\"] = xdata\n",
    "    res_dict[\"ORBIT_CNT\"] = orbit\n",
    "    res_dict[\"SL\"] = sl\n",
    "\n",
    "    return res_dict, xdata, ydata, reco_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid hits: 54952\n",
      "Chosen df eligible for computing? True\n",
      "Not optimized:\n",
      "Time 0.04058319420000771 s, Memory 0.091308 MB\n",
      "Optimized:\n",
      "Time 0.04070788639946841 s, Memory 0.082303 MB\n"
     ]
    }
   ],
   "source": [
    "n_iter  = 5\n",
    "events  = getEvents_o(DATA_FNAME, cfg, 0)\n",
    "df_E    = events[5]\n",
    "chamber = [df_E[df_E[\"SL\"] == i] for i in range(4)]\n",
    "df      = chamber[1]\n",
    "print(\"Chosen df eligible for computing?\", len(pd.unique(df.LAYER)) >=3 )\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "t_o       = timeit('compute_o(df)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_o = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.reset_peak()\n",
    "\n",
    "t_no       = timeit('compute_no(df)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_no = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"Not optimized:\\nTime {0} s, Memory {1} MB\\nOptimized:\\nTime {2} s, Memory {3} MB\".format(t_no, peak_no/10**6, t_o, peak_o/10**6) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# *****************************************************************************\n",
    "# COMPUTE EVENT\n",
    "# *****************************************************************************\n",
    "\n",
    "def computeEvent(df_E):\n",
    "\n",
    "    chamber = [df_E[df_E[\"SL\"] == i] for i in range(4)]\n",
    "    event_reco_df = pd.DataFrame()\n",
    "\n",
    "    for df in chamber:\n",
    "        if len(pd.unique(df.LAYER)) < 3:\n",
    "            continue\n",
    "        \n",
    "        chamber_reco_df = compute_o(df)\n",
    "        event_reco_df = pd.concat(\n",
    "            [event_reco_df, chamber_reco_df], axis=0, ignore_index=True\n",
    "        )\n",
    "\n",
    "    if len(event_reco_df)==0:\n",
    "        return None\n",
    "\n",
    "    return event_reco_df\n",
    "\n",
    "def getRecoResults(events):\n",
    "    resultsDf = []\n",
    "\n",
    "    for df_E in events:\n",
    "        event_reco_df = computeEvent(df_E)\n",
    "        if event_reco_df is None:\n",
    "            continue\n",
    "        if len(event_reco_df)==0:\n",
    "            continue\n",
    "        resultsDf.append(event_reco_df)\n",
    "\n",
    "    return resultsDf\n",
    "\n",
    "# *****************************************************************************\n",
    "# MULTIPROCESSING\n",
    "# *****************************************************************************\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def getRecoResults_mp(events):\n",
    "    \n",
    "    pool = Pool(processes=cpu_count()-2)\n",
    "    \n",
    "    result = pool.map_async(computeEvent, events)\n",
    "    resultsDf = result.get()\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    resultsDf = [x for x in resultsDf if x is not None]\n",
    "\n",
    "    return resultsDf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n",
      "/home/alberto/anaconda3/lib/python3.9/site-packages/scipy/optimize/minpack.py:833: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  warnings.warn('Covariance of the parameters could not be estimated',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not optimized:\n",
      "Time 436.2627538680026 s, Memory 34.993542 MB\n",
      "Optimized:\n",
      "Time 157.51661917399906 s, Memory 24.963305 MB\n"
     ]
    }
   ],
   "source": [
    "n_iter  = 1\n",
    "#events  = getEvents_o(DATA_FNAME, cfg, 0)\n",
    "\n",
    "tracemalloc.start()\n",
    "\n",
    "t_o       = timeit('getRecoResults_mp(events)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_o = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.reset_peak()\n",
    "\n",
    "t_no       = timeit('getRecoResults(events)', number = n_iter, globals=globals()) / n_iter\n",
    "_, peak_no = tracemalloc.get_traced_memory()\n",
    "\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"Not optimized:\\nTime {0} s, Memory {1} MB\\nOptimized:\\nTime {2} s, Memory {3} MB\".format(t_no, peak_no/10**6, t_o, peak_o/10**6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f70c2c6f75f001c2435d8036b6cc1833b789af896ffe22ab30918cedbc10c86"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
